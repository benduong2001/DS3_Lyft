{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math as math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = \"*\"\n",
    "# folderpath = \"C:\\\\Users\\\\Benson\\\\Desktop\"\n",
    "file = folderpath + \"\\\\lyftlong\\\\rand_agents_table0.csv\"\n",
    "at = pd.read_csv(file)\n",
    "file = folderpath + \"\\\\lyftlong\\\\rand_frames_table1.csv\"\n",
    "ft = pd.read_csv(file)\n",
    "file = folderpath +  \"\\\\lyftlong\\\\rand_scenes_table1.csv\"\n",
    "st = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scene_Temporal_Info:\n",
    "    def __init__(self, scene_table: pd.DataFrame):\n",
    "        # NOTE: scene_table is already filtered to be only 1 scene\n",
    "        self.scene_table = scene_table\n",
    "        self.AV_locations = list(zip(list(self.scene_table['ego_translation_x']), \n",
    "                                     list(self.scene_table['ego_translation_y'])))\n",
    "        self.velocities = []\n",
    "        self.translations = []\n",
    "        self.unit_dotprods = []\n",
    "    \n",
    "    def _unit(self, a: [float, float]) -> [float, float]:\n",
    "        \"\"\"Gets the unit of vector a. Returns zero vector if norm causes zero division\n",
    "        Args:\n",
    "            a ([float, float]): vector a\n",
    "        Returns:\n",
    "            float: the unit of vector a\n",
    "        \"\"\"\n",
    "        norm = self._vector_norm(a)\n",
    "        if norm == 0:\n",
    "            return [0.0, 0.0]\n",
    "        else:\n",
    "            return [a_i/norm for a_i in a]\n",
    "    def _vector_norm(self, a: [float]) -> float:\n",
    "        \"\"\"Gets the norm of vector a\n",
    "        Args:\n",
    "            a ([float, float]): vector a\n",
    "        Returns:\n",
    "            float: the norm of both vectors\n",
    "        \"\"\"\n",
    "        return (sum([a_i**2 for a_i in a]))**(1/2)\n",
    "    def _dotprod(self, a, b) -> float:\n",
    "        \"\"\"Gets the dotprod of vectors a and b\n",
    "        Args:\n",
    "            a ([float, float]): vector a\n",
    "            b ([float, float]): vector b\n",
    "        Returns:\n",
    "            float: the dotprods of both vectors\n",
    "        \"\"\"\n",
    "        return sum([ai*bi for ai, bi in zip(a, b)])\n",
    "    def _translation(self, a: [float, float], b: [float, float]) -> [float, float]:\n",
    "        \"\"\"Gets the translation coords of points a and b\n",
    "        Args:\n",
    "            a ([float, float]): point a\n",
    "            b ([float, float]): point b\n",
    "        Returns:\n",
    "            [float, float]: distance in x and distance in y between both points\n",
    "        \"\"\"\n",
    "        ax, ay = a\n",
    "        bx, by = b\n",
    "        return [(bx - ax), (by - ay)]\n",
    "    def set_velocities(self):\n",
    "        velocities = []\n",
    "        self.translations.clear()\n",
    "        for i in range(1, len(self.AV_locations)):\n",
    "            pointB = self.AV_locations[i]\n",
    "            pointA = self.AV_locations[i - 1]\n",
    "            side_length = self._translation(pointA, pointB)\n",
    "            self.translations.append(side_length)\n",
    "            velocity = self._vector_norm(side_length)\n",
    "            velocities.append(velocity)\n",
    "        self.velocities = velocities\n",
    "        assert len(self.translations) == len(self.velocities)\n",
    "        assert len(self.velocities)+1 == len(self.AV_locations)\n",
    "        return velocities\n",
    "    def set_unit_dotprods(self):\n",
    "        if len(self.translations) == 0:\n",
    "            self.set_velocities()\n",
    "        unit_dotprods = []\n",
    "        for i in range(1, len(self.translations)):\n",
    "            vectB = self.translations[i]\n",
    "            vectA = self.translations[i - 1]\n",
    "            unit_dotprod = self._dotprod(self._unit(vectA), \n",
    "                                         self._unit(vectB))\n",
    "            unit_dotprods.append(unit_dotprod)\n",
    "        self.unit_dotprods = unit_dotprods\n",
    "        return unit_dotprods        \n",
    "    def get_unit_dotprods(self) -> [float]:\n",
    "        assert self.unit_dotprods != []\n",
    "        return [0.0, 0.0] + self.unit_dotprods\n",
    "    def get_velocities(self) -> [float]:\n",
    "        assert self.velocities != []\n",
    "        return [0.0] + self.unit_dotprods\n",
    "    def run(self):\n",
    "        self.set_velocities()\n",
    "        self.set_unit_dotprods()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def scene_table_subset(scene_index: int, table: pd.DataFrame = ft) -> pd.DataFrame:\n",
    "    scene_table = table[table.scene_index == scene_index]\n",
    "    return scene_table\n",
    "scene_indices = pd.unique(ft['scene_index'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scene_indices = [ 7827, 15982, 10378,   154,  9380, 15002,  4455,  8285, 10522,\n",
    "        2810,  1233,  1094,  3475, 13521,  2989,   385, 13242, 15073,\n",
    "         721,  5601,  9884,  3818,  1372,  8029,  9520, 14617,  3043,\n",
    "       13122, 13699, 12155, 15371,  5025,  1495,  8679, 13317,   204,\n",
    "       14294, 11121, 13106, 14812,  8581,  9953,  5475,  8368,  1162,\n",
    "       12928,  2595, 15782,   378,  3163, 15761,  2259, 15022, 15410,\n",
    "         665,  4781, 10834, 12188,  1820, 12334, 15643,  2180,  2281,\n",
    "        6235, 10847, 11405, 10210, 14560,  8968,  4386,  6303, 11197,\n",
    "       14339,  2013,  9767, 13168, 11383, 14898,   296,  6343, 12055,\n",
    "         112, 13893, 11414, 15559, 11667, 15367,  2547,   587, 11458,\n",
    "       13215, 15416, 14090,  2367, 12803,  7992, 10719, 11029,  8566,\n",
    "       15427]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rand_index = np.random.choice(scene_indices)\n",
    "scene_table = scene_table_subset(rand_index)\n",
    "tmp_info = Scene_Temporal_Info(scene_table)\n",
    "tmp_info.run()\n",
    "print(rand_index)\n",
    "# plt.ylim(-1, 1)\n",
    "plt.plot(tmp_info.unit_dotprods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(tmp_info.velocities) # in a given scene\n",
    "# velocities over a given scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unit_dotprods = []\n",
    "for scene_index in scene_indices:\n",
    "    scene_table = scene_table_subset(scene_index)\n",
    "    tmp_info = Scene_Temporal_Info(scene_table)\n",
    "    tmp_info.run()\n",
    "    all_unit_dotprods = all_unit_dotprods + tmp_info.unit_dotprods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = tmp_info.get_velocities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_velocities = []\n",
    "all_velocities_adjusted = []\n",
    "for scene_index in scene_indices:\n",
    "    scene_table = scene_table_subset(scene_index)\n",
    "    tmp_info = Scene_Temporal_Info(scene_table)\n",
    "    tmp_info.run()\n",
    "    all_velocities_adjusted = all_velocities_adjusted + [tmp_info.velocities[0]] + tmp_info.velocities\n",
    "    all_velocities = all_velocities + tmp_info.velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr = pd.DataFrame()\n",
    "dpr['dot_products'] = all_unit_dotprods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_range(dp):\n",
    "    intervals = [(-1.0, -0.8),\n",
    "     (-0.8, -0.6),\n",
    "     (-0.6, -0.4),\n",
    "     (-0.4, -0.2),\n",
    "     (-0.2, 0.0),\n",
    "     (0.0, 0.2),\n",
    "     (0.2, 0.4),\n",
    "     (0.4, 0.6),\n",
    "     (0.6, 0.8),\n",
    "     (0.8, 1.0)]\n",
    "    ranks = [-1.0, -0.8, -0.6, -0.4, -0.2, 0.0, 0.2, 0.4, 0.6, 0.8]\n",
    "    for i in range(len(intervals)):\n",
    "        intvl = intervals[i]\n",
    "        if dp > intvl[0] and dp <= intvl[1]:\n",
    "            return ranks[i]\n",
    "        if dp > 1.0:\n",
    "            return 0.8\n",
    "        \n",
    "dpr['range'] = [get_range(dp) for dp in all_unit_dotprods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(list(range(24637)), all_unit_dotprods, s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(all_velocities) # in a given scene\n",
    "plt.scatter(list(range(24737)), all_velocities, s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unit_dotprods.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dpr.sort_values('dot_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpr.groupby('range', sort=True).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dpr.to_csv(\"C:\\\\Users\\\\Benson\\\\Desktop\\\\lyftlong\\\\rand_norm_dotprods_table1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTING UNKNOWN TRAFFIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fta0 = ft['agent_index_interval_start']\n",
    "fta1 = ft['agent_index_interval_end']\n",
    "\n",
    "agents_amount = []\n",
    "for i in range(len(ft)):\n",
    "    a0i = fta0[i]\n",
    "    a1i = fta1[i]\n",
    "    agents_amount.append(a1i - a0i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(agents_amount)\n",
    "plt.title(\"Histogram of frequency of agent amounts\")\n",
    "plt.ylabel(\"Frequency of agent amount\")\n",
    "plt.xlabel(\"Agent amount for a given frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ft.to_csv(\"C:\\\\Users\\\\Benson\\\\Desktop\\\\lyftlong\\\\rand_frames_table1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_distance_agents(at = at):\n",
    "        at_temp = at[['centroid_x','centroid_y','frame_index']]\n",
    "        ft_temp = ft[['ego_translation_x', 'ego_translation_y', 'frame_index']]\n",
    "        at_temp = at_temp.merge(ft_temp, on=\"frame_index\")\n",
    "        dx = (at_temp['centroid_x'] - at_temp['ego_translation_x'])**2\n",
    "        dy = (at_temp['centroid_y'] - at_temp['ego_translation_y'])**2\n",
    "        dist = (dx + dy)**(1/2)\n",
    "        at_temp['dist'] = dist\n",
    "        meandist = at_temp.groupby('frame_index',sort=False).mean()['dist']\n",
    "        return meandist.values\n",
    "\n",
    "mean_dist_values = get_mean_distance_agents(at )\n",
    "ft['Mean Distance from Agents'] = mean_dist_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(range(len(ft))), ft['Mean Distance from Agents'], s=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_velocities_adjusted.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(ft['Mean Distance from Agents'], all_velocities_adjusted, s=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(ft['Mean Distance from Agents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting thershold radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_dotprods = []\n",
    "\n",
    "for i in range(100):\n",
    "    si = scene_indices[i]\n",
    "    sft = ft[ft.scene_index == si]\n",
    "    mowd = Scene_Temporal_Info(sft)\n",
    "    mowd.run()\n",
    "    dpi = mowd.get_unit_dotprods()\n",
    "    frame_dotprods = frame_dotprods + dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft['dotprod'] = frame_dotprods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Table_Aggregation:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def aggregator(self, table: pd.DataFrame = None) -> np.array:\n",
    "        \"\"\" Collapses a table of a certain frame_index in a source table into an array\n",
    "        Args:\n",
    "            table (pd.DataFrame): the subset table of the source table with a certain frame_index\n",
    "        Returns:\n",
    "            np.array: the horizontal aggregation of the columns in the subsettted table\n",
    "        \"\"\"\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent_Aggregation (Table_Aggregation):\n",
    "    def __init__(self, table: pd.DataFrame = at, columns: [str] = []):\n",
    "        super(Agent_Aggregation, self).__init__()\n",
    "        self.table = table # agent_table\n",
    "        self.columns = columns\n",
    "        subset_table = table[columns].copy() #[table.frame_index == frame_index][columns].copy()\n",
    "        self.subset_table = subset_table\n",
    "    def aggregator(self, table: pd.DataFrame = None) -> pd.DataFrame:\n",
    "        if table == None:\n",
    "            table = self.subset_table \n",
    "        table['temp_index'] = table['frame_index']\n",
    "        avgs = table.groupby('temp_index', sort=False).mean()\n",
    "        return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at['size'] = at['extent_x'] * at['extent_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1 = Agent_Aggregation(table = at,\n",
    "                        columns = [\n",
    "                            \"size\",\n",
    "                            \"frame_index\",\n",
    "                            \"velocity_x\",\n",
    "                            \"velocity_y\",\n",
    "                            \"yaw\"\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn1_table = nn1.aggregator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft2 = ft.merge(nn1_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Frame_Instance:\n",
    "    def __init__(self, frame_0_array: np.array, frame_1_transl: np.array):\n",
    "        self.frame_0_array = frame_0_array\n",
    "        self.frame_1_translation = frame_1_transl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_scenes_indices = pd.unique(ft2['scene_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_instances = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_encoder(frame_0_row):\n",
    "    reverse = frame_0_row['dotprod']\n",
    "    frame_0_row = frame_0_row.drop(['dotprod',\n",
    "    'timestamp', \n",
    "    'agent_index_interval_start', \n",
    "    'agent_index_interval_end',\n",
    "    'traffic_lights_start', \n",
    "    'traffic_lights_end',\n",
    "    'frame_index', 'scene_index'])\n",
    "    input_ = np.array(frame_0_row)\n",
    "    if reverse < 0:\n",
    "        label = 0\n",
    "    if reverse >= 0:\n",
    "        label = 1\n",
    "    assert len(input_) == 17\n",
    "    return input_, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(ft2)):\n",
    "    row = ft2.iloc[i]\n",
    "    input_, label = frame_encoder(row)\n",
    "    frame_instance = Frame_Instance(input_, label)\n",
    "    frame_instances.append(frame_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for frame_instance in frame_instances:\n",
    "    X.append(list(frame_instance.frame_0_array))\n",
    "    if frame_instance.frame_1_translation == 0:\n",
    "        y.append(0)\n",
    "    else:\n",
    "        y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame_instances = []\n",
    "for i in range(len(X)):\n",
    "    input_ = X[i]\n",
    "    label = y[i]\n",
    "    frame_instance = Frame_Instance(input_, label)\n",
    "    new_frame_instances.append(frame_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame_instances = np.array(new_frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(new_frame_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROPORTION = 0.8\n",
    "TRAIN_PROPORTION_INDEXER = int(len(new_frame_instances) * TRAIN_PROPORTION)\n",
    "nrevtr = new_frame_instances[:TRAIN_PROPORTION_INDEXER]\n",
    "nrevt = new_frame_instances[TRAIN_PROPORTION_INDEXER:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN_PROPORTION_INDEXER len(new_frame_instances)\n",
    "len(nrevtr)\n",
    "9912 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_frame_instances)\n",
    "np_frame_instances[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dataset = np.array(nrevtr)\n",
    "Test_Dataset = np.array(nrevt)\n",
    "np.random.shuffle(Train_Dataset)\n",
    "np.random.shuffle(Test_Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "for frame_instance in Train_Dataset:\n",
    "    train_xi = frame_instance.frame_0_array\n",
    "    train_x.append(train_xi)\n",
    "    train_yi = frame_instance.frame_1_translation\n",
    "    train_y.append(train_yi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "for frame_instance in Test_Dataset:\n",
    "    test_xi = frame_instance.frame_0_array\n",
    "    test_x.append(test_xi)\n",
    "    test_yi = frame_instance.frame_1_translation\n",
    "    test_y.append(test_yi)\n",
    "\n",
    "# test_x = [frame_instance.frame_0_array for frame_instance in Test_Dataset]\n",
    "# test_y = [frame_instance.frame_1_translation for frame_instance in Test_Dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "test_x = np.array(test_x)\n",
    "test_y = np.array(test_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(Dense(16, input_shape=(17,)))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(4))\n",
    "model.add(Dense(2))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_x, train_y, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes = 0\n",
    "for i in range(len(test_y)):\n",
    "    if i % 2000 == 0 and i != 0:\n",
    "        print(\"{0} of {1} samples tested\".format(i, len(test_y)))\n",
    "    pred = model.predict(np.array([test_x[i],]))[0][0]\n",
    "    target = (test_y[i])\n",
    "    if target >= .5:\n",
    "        target == 1\n",
    "    else:\n",
    "        target == 0\n",
    "    if target == pred:\n",
    "        successes += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "successes/len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
