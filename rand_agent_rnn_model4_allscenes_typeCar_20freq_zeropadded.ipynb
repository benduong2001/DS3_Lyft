{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rand Agent Table with RNN for Time Series:\n",
    "\n",
    "MODEL 4\n",
    "\n",
    "\n",
    "* For agents with type Car only\n",
    "* For all scenes \n",
    "* 20 most frequent agents only\n",
    "* zero-padded (front padding included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at this for more info on multiple parallel series with RNN: https://machinelearningmastery.com/how-to-develop-lstm-models-for-time-series-forecasting/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderpath = \"*\"\n",
    "folderpath = \"C:\\\\Users\\\\Benson\\\\Desktop\"\n",
    "file = folderpath + \"\\\\lyftlong\\\\rand_agents_table0.csv\"\n",
    "at = pd.read_csv(file)\n",
    "file = folderpath + \"\\\\lyftlong\\\\rand_frames_table1.csv\"\n",
    "ft = pd.read_csv(file)\n",
    "file = folderpath +  \"\\\\lyftlong\\\\rand_scenes_table1.csv\"\n",
    "st = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = at.merge(ft[['frame_index', 'scene_index']], on='frame_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at = at[at.PERCEPTION_LABEL_CAR == 1] \n",
    "# FEATURE: filter to only types with Car; uncomment the above to include all agent types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atcols = ['centroid_x', 'centroid_y', 'track_id', 'frame_index', 'scene_index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrnn = at[atcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_indices = pd.unique(at['scene_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrnn1 = atrnn[atrnn.scene_index == scene_indices[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrnn1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_parallel_input_series = pd.DataFrame()\n",
    "apis = agent_parallel_input_series\n",
    "# apis will be the dataframe that we will partiton for the rnn data table information\n",
    "\n",
    "atrnn1s = atrnn1 #.sort_values(['track_id', 'frame_index'])\n",
    "\n",
    "track_ids = pd.unique(atrnn1s['track_id'])\n",
    "NUM_ENTITIES = len(track_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FEATURE: We will only take the 20 most frequent track ids. Set N_MOST_FREQUENT to NUM_ENTITIES if you don't want that\n",
    "\n",
    "freq_track_ids = atrnn1s.groupby(['track_id']).count().reset_index()\n",
    "\n",
    "N_MOST_FREQUENT = 20 # NUM_ENTITIES\n",
    "assert N_MOST_FREQUENT <= NUM_ENTITIES\n",
    "def get_n_most_frequent(n: int = NUM_ENTITIES):\n",
    "    \"\"\" get's track ids of the n most frequent entities in a scene.\"\"\"\n",
    "    global freq_track_ids\n",
    "    freq_track_ids = freq_track_ids.sort_values('frame_index', ascending=False)\n",
    "    return freq_track_ids['track_id'].iloc[:20].values\n",
    "track_ids = get_n_most_frequent(N_MOST_FREQUENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis_cols = ['centroid_x', 'centroid_y'] + ['frame_index'] #  ['velocity_x', 'velocity_y'] +  ['frame_index'] + ['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis_frame_indices = pd.unique(atrnn1['frame_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis['frame_index'] = apis_frame_indices # added to the apis table so that each agent can be merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(track_ids)):\n",
    "    if i%100 == 0:\n",
    "        print(\"{0} of {1}\".format(i, len(track_ids)))\n",
    "    ti = track_ids[i]\n",
    "    # for each track id, get it's subset in atrnn1s\n",
    "    atrnn1sti = atrnn1s[atrnn1s.track_id == ti]\n",
    "    # get these columns only\n",
    "    atrnn1sti = atrnn1sti[apis_cols]\n",
    "    # rename the columns by labelling it with it's track id\n",
    "    atrnn1sti = atrnn1sti.add_prefix('ti{0}_'.format(str(ti)))\n",
    "    # undo apis index's renaming for joining to apis\n",
    "    atrnn1sti.rename(columns = {\"ti{0}_frame_index\".format(str(ti)): \"frame_index\"},  \n",
    "                     inplace = True) \n",
    "    # LEFT OUTER JOIN with APIS, atrnn1sti\n",
    "    apis = pd.merge(apis, atrnn1sti, on='frame_index', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis = apis.drop(['frame_index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apis\n",
    "# if you set N_MOST_FREQUENT to 20, there should be 40 columns only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE: replace all NaN's with zeros\n",
    "apis = apis.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atrnn1 = apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_partitions(ar: np.array, step: int = 3) -> np.array:\n",
    "    len_ar = len(ar)\n",
    "    partitions = np.array([])\n",
    "    for i in range(len_ar - step):\n",
    "        X_partition = ar[i: i + step]\n",
    "        y_partition = ar[i + step]\n",
    "        partition = dict()\n",
    "        partition['X'] = ((X_partition))\n",
    "        partition['y'] = ((y_partition))\n",
    "        partitions = np.append(partitions, partition)\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSTEPS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = make_partitions(np.array(atrnn1), NSTEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PROPORTION = 0.8\n",
    "TRAIN_PROPORTION_INDEXER = int(len(atrnn1) * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(len(partitions)): # [:TRAIN_PROPORTION_INDEXER]:\n",
    "    partition = partitions[i]\n",
    "    if i <= TRAIN_PROPORTION_INDEXER:\n",
    "        X_train.append(partition['X'])\n",
    "        y_train.append(partition['y'])\n",
    "    else:\n",
    "        X_test.append(partition['X'])\n",
    "        y_test.append(partition['y'])        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = NSTEPS\n",
    "n_features = len(atrnn1.columns)\n",
    "\n",
    "act = 'tanh'\n",
    "act1 = 'relu'\n",
    "recact = 'sigmoid'\n",
    "retseq = True\n",
    "\n",
    "#### define model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation=act, recurrent_activation=recact, return_sequences=retseq, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation=act))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.fit(X_train, y_train, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100,input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50, activation = 'tanh', return_sequences = True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(25, activation = 'tanh', return_sequences = False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "model.compile(loss='mse', optimizer='adam', metrics = ['accuracy'])\n",
    "\n",
    "model_info = model.fit(X_train, y_train, epochs=300, verbose=0)\n",
    "print(model_info.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = X_test[0]\n",
    "y_targ = y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inp = X_test[0]\n",
    "y_targ = y_test[0]\n",
    "\n",
    "x_inp = x_inp = x_inp.reshape((1, n_steps, n_features))\n",
    "x_inp.shape\n",
    "\n",
    "y_hat = model.predict(x_inp, verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = model.evaluate(X_test, y_test, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECTION LIMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(x_inp, verbose=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8.4155383e+02, -1.4250477e+03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_targ, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/len(y_hat))*np.sqrt(((y_hat - y_targ)**2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "CosineSimilarity = 1 - spatial.distance.cosine(y_hat, y_targ)\n",
    "CosineSimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(y_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
